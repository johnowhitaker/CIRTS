{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Selection\n",
    "\n",
    "This notebook will attempt to provide some justification for the particular model chosen for use throughout my final year project. I'll run through my thinking, show how the neural network approach performs in relation to some other likely choices and re-create my hyper-parameter tuning process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "One goal of my project is to answer a fairly broad question: can we use machine learning to make inferences from the readings we'll be taking.\n",
    "\n",
    "To answer this, we need to do some kind of machine learning. There will be many sub-tasks, both classification and regression. For each one, we could go through a rigorous model selection approach, but it's nice to have one or two good general purpose models that we can use. We don't care so much about the question 'what is the absolute best performance we could achieve here' - all we want to know is whether ML can be useful in solving a given problem. \n",
    "\n",
    "So we want to find one or two models that can generalize to the different tasks we'll be trying. The chosen models will need to have the following charachteristics:\n",
    "- General purpose. Some algorithms might work for one specific problem, but we want a model that can be easily adapted to the different situations\n",
    "- Robust. We will be using fairly small training datasets, so the model will need some way of combatting overfitting. There is a danger that an overly complicated model will simply fit the noise in the training data and not generalize well.\n",
    "- Capable of fitting complex functions. Simple linear models might work for some of the problems considered, but a good model would be able to handle the non-linearities inherent in our experimental setup. Light scatters, diffracts, reflects and attenuates. A more complex model would probably be better suited to this kind of problem.\n",
    "\n",
    "With this in mind, let's load up some data and begin our experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jonathan/.local/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>quadrant</th>\n",
       "      <th>object</th>\n",
       "      <th>object_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>740</td>\n",
       "      <td>738</td>\n",
       "      <td>733</td>\n",
       "      <td>736</td>\n",
       "      <td>744</td>\n",
       "      <td>727</td>\n",
       "      <td>729</td>\n",
       "      <td>749</td>\n",
       "      <td>721</td>\n",
       "      <td>734</td>\n",
       "      <td>...</td>\n",
       "      <td>554</td>\n",
       "      <td>721</td>\n",
       "      <td>728</td>\n",
       "      <td>727</td>\n",
       "      <td>724</td>\n",
       "      <td>723</td>\n",
       "      <td>727</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>747</td>\n",
       "      <td>736</td>\n",
       "      <td>736</td>\n",
       "      <td>719</td>\n",
       "      <td>729</td>\n",
       "      <td>734</td>\n",
       "      <td>721</td>\n",
       "      <td>734</td>\n",
       "      <td>729</td>\n",
       "      <td>722</td>\n",
       "      <td>...</td>\n",
       "      <td>543</td>\n",
       "      <td>740</td>\n",
       "      <td>721</td>\n",
       "      <td>741</td>\n",
       "      <td>723</td>\n",
       "      <td>716</td>\n",
       "      <td>724</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>738</td>\n",
       "      <td>727</td>\n",
       "      <td>730</td>\n",
       "      <td>721</td>\n",
       "      <td>738</td>\n",
       "      <td>734</td>\n",
       "      <td>722</td>\n",
       "      <td>741</td>\n",
       "      <td>734</td>\n",
       "      <td>728</td>\n",
       "      <td>...</td>\n",
       "      <td>552</td>\n",
       "      <td>739</td>\n",
       "      <td>716</td>\n",
       "      <td>714</td>\n",
       "      <td>728</td>\n",
       "      <td>720</td>\n",
       "      <td>740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>748</td>\n",
       "      <td>734</td>\n",
       "      <td>738</td>\n",
       "      <td>737</td>\n",
       "      <td>756</td>\n",
       "      <td>743</td>\n",
       "      <td>722</td>\n",
       "      <td>744</td>\n",
       "      <td>728</td>\n",
       "      <td>733</td>\n",
       "      <td>...</td>\n",
       "      <td>550</td>\n",
       "      <td>746</td>\n",
       "      <td>730</td>\n",
       "      <td>724</td>\n",
       "      <td>723</td>\n",
       "      <td>713</td>\n",
       "      <td>730</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>744</td>\n",
       "      <td>737</td>\n",
       "      <td>740</td>\n",
       "      <td>746</td>\n",
       "      <td>738</td>\n",
       "      <td>746</td>\n",
       "      <td>717</td>\n",
       "      <td>738</td>\n",
       "      <td>737</td>\n",
       "      <td>734</td>\n",
       "      <td>...</td>\n",
       "      <td>539</td>\n",
       "      <td>736</td>\n",
       "      <td>725</td>\n",
       "      <td>731</td>\n",
       "      <td>717</td>\n",
       "      <td>725</td>\n",
       "      <td>732</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9     ...        65   66  \\\n",
       "0  740  738  733  736  744  727  729  749  721  734     ...       554  721   \n",
       "1  747  736  736  719  729  734  721  734  729  722     ...       543  740   \n",
       "2  738  727  730  721  738  734  722  741  734  728     ...       552  739   \n",
       "3  748  734  738  737  756  743  722  744  728  733     ...       550  746   \n",
       "4  744  737  740  746  738  746  717  738  737  734     ...       539  736   \n",
       "\n",
       "    67   68   69   70   71  quadrant  object  object_name  \n",
       "0  728  727  724  723  727         0       0        empty  \n",
       "1  721  741  723  716  724         0       0        empty  \n",
       "2  716  714  728  720  740         0       0        empty  \n",
       "3  730  724  723  713  730         0       0        empty  \n",
       "4  725  731  717  725  732         0       0        empty  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load up the required libraries\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Load the first dataset\n",
    "df1 = pd.read_csv('dataset_2q.csv')\n",
    "df1 = df1.drop('Unnamed: 0', axis=1)\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data comes from the ring of 8. Each row contains 72 readings. 8 ADC readings from the PTs with no LEDs illuminated, 8 with the first LED lit, 8 with the second etc. These will be the inputs to our model. The quadrant and object columns are the output variables. We want a model to be able to predict these values based on the inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given model, we'll split the data into a training set and a test set. We train the model with the training data, then see how well it performs on the (never before seen) test data. Here, I'm only showing the score for one run. When doing these tests, I generally repeat many times for different (random) test and train sets generated from the initial dataset. This is called cross-validation, and later in this notebook I'll switch to using that to get more accurate comparative scores for choosing the best model. For now, we'll take the more simplistic approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 0.8013333333333333\n",
      "Score (test data) 0.722\n"
     ]
    }
   ],
   "source": [
    "# Split the data. X will be the inputs, Y the desired output\n",
    "X = df1[[str(i) for i in range(72)]] # The readings\n",
    "y = df1['object'] # What object is in the ring\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Initiate a model. Let's try a simple linear model first. Since this is a classification task, \n",
    "# the logistic regression model (aka MaxEnt, logit regression, log-linear classifier) is the typical choice\n",
    "model = LogisticRegression() # We'll leave the parameters as default for now\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Score the model on the training data and the test data\n",
    "print('Score (training data)', model.score(X_train, y_train))\n",
    "print('Score (test data)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "72% accuracy. Not bad! Notice that the score is beter for the training data (expected) but still decent for the test data. This is because by default the model includes a regularization parameter to prevent overfitting. We'll see some models that don't do as well on the test but score nearly 100% on the training data because they don't address this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next model we'll try is a classic for classification :) Support vector machines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 0.542\n",
      "Score (test data) 0.522\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "model = LinearSVC()\n",
    "model.fit(X_train, y_train)\n",
    "print('Score (training data)', model.score(X_train, y_train))\n",
    "print('Score (test data)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model = SVC()\n",
    "model.fit(X_train, y_train)\n",
    "print('Score (training data)', model.score(X_train, y_train))\n",
    "print('Score (test data)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first one does pretty badly, and the second is clearly suffering from overfitting. I'll increase the regularization parameter untill we start to get a more generalizeable model. We do this by setting the 'gamma' parameter. Lower gamma means more emphasis on the regularization term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (test data) 0.19 Gamma: 0.1\n",
      "Score (test data) 0.19 Gamma: 0.01\n",
      "Score (test data) 0.458 Gamma: 0.001\n",
      "Score (test data) 0.864 Gamma: 0.0001\n",
      "Score (test data) 0.806 Gamma: 1e-05\n"
     ]
    }
   ],
   "source": [
    "for g in [0.1, 0.01, 0.001, 0.0001, 0.00001]:\n",
    "    model = SVC(gamma=g)\n",
    "    model.fit(X_train, y_train)\n",
    "    print('Score (test data)', model.score(X_test, y_test), 'Gamma:', g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This introduces the idea of hyperparameter tuning. We're tweaking one of the defining attributes of the model and seeing how we can maximise performance. In this case, with gamma=0.0001 we see much better performance than with the default value. This is now our best performing model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could probably get our score up a little bit more by tuning some other parameters and tweaking the gamma ever so slightly. But let's move on to other types of models. Here, I'll try a decision tree approach, followed my one of my favourite (for nostalgic reasons) models - Random Forest Classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.646\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "model = tree.DecisionTreeClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print('Score (training data)', model.score(X_train, y_train))\n",
    "print('Score (test data)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 0.814\n",
      "Score (test data) 0.666\n"
     ]
    }
   ],
   "source": [
    "# And after some tuning, removed for brevity, we still get pretty much the same result\n",
    "model = tree.DecisionTreeClassifier(max_depth = 8, min_samples_leaf=1)\n",
    "model.fit(X_train, y_train)\n",
    "print('Score (training data)', model.score(X_train, y_train))\n",
    "print('Score (test data)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not great. Dtrees are not really used much - too simple and prone to overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 0.9953333333333333\n",
      "Score (test data) 0.742\n"
     ]
    }
   ],
   "source": [
    "# First with defualt values\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print('Score (training data)', model.score(X_train, y_train))\n",
    "print('Score (test data)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.866\n"
     ]
    }
   ],
   "source": [
    "# Trying some better values for the important parameters. I arrive at these via intuition and\n",
    "# a bit of experimentation. I'm pretty good at it - see the leaderboard of the competition \n",
    "# ongoing at zindi.africa :) There is a general method which one can follow to optimize a random forest model\n",
    "model = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_leaf=2)\n",
    "model.fit(X_train, y_train)\n",
    "print('Score (training data)', model.score(X_train, y_train))\n",
    "print('Score (test data)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is roughly as good as the best SVC model, and we haven't yet done much tuning. But scoring on this one test set is a bit misleading, and we might end up picking paramteres that only work for this one random split. So at this point I'll do some housekeeping and introduce a better scoring function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rforest score: 2.9125\n",
      "SVC score: 2.7100000000000004\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "# Our new scoring function. Takes a model as input, as well as X and y. Does 5 splits and returns the sum of the scores\n",
    "def cvs(model, X, y, ns=5):\n",
    "    k_fold = KFold(n_splits=ns)\n",
    "    score = 0\n",
    "    for trains, tests in k_fold.split(X):\n",
    "        model.fit(X.values[trains], y.values[trains])\n",
    "        score += model.score(X.values[tests],y.values[tests])\n",
    "    return score\n",
    "\n",
    "model1 = RandomForestClassifier(n_estimators=200, max_depth=15, min_samples_leaf=2)\n",
    "model2 = model = SVC(gamma=0.0001)\n",
    "\n",
    "print('Rforest score:', cvs(model1, X, y))\n",
    "print('SVC score:', cvs(model2, X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scoring is simple - bigger is better. We could adjust the function to give a meaningful value but all I care about for now is comparison. Notice it takes ages, so I'll stick to the old way untill we need to settle a close contest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the fun part - neural networks. I have big hopes for this approach, and not just because I've done this before. They're good at this sort of thing. Veng-Pedersen, P. and Modi, N.B., 1992. say they are \"are recognized mainly in terms of their adaptive learning and self-organization features and their nonlinear processing capability and are considered most suitable to deal with complex multivariate systems that are poorly understood and difficult to model by classical inductive, logically structured modeling techniques.”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 0.2926666666666667\n",
      "Score (test data) 0.306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "print('Score (training data)', model.score(X_train, y_train))\n",
    "print('Score (test data)', model.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What!? That's terrible! Almost as bad as random guessing (there are 5 classes here). What could we be doing wrong?\n",
    "\n",
    "Well, one important fact: NNs are messed up by input scaling. So the first thing we should do is scale our inputs down to a sensoble range. This is a common problem with a library to solve it for us, so here we go. Take two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.87\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# This will look at the maximum values and scale accordingly to keep inputs small and manageable\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "model = MLPClassifier()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Score (training data)', model.score(X_train_scaled, y_train))\n",
    "print('Score (test data)', model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bam. Top score right away:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.53"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvs(model, pd.DataFrame(scaler.transform(X)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.725"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And the parameters I used for the project.\n",
    "model = MLPClassifier(hidden_layer_sizes=(20, 20, 20), max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Score (training data)', model.score(X_train_scaled, y_train))\n",
    "print('Score (test data)', model.score(X_test_scaled, y_test))\n",
    "cvs(model, pd.DataFrame(scaler.transform(X)), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So why these parameters? Lets vary some things and show that this is the right choice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6700000000000004"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Less hidden layers\n",
    "model = MLPClassifier(hidden_layer_sizes=(20, 20), max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Score (training data)', model.score(X_train_scaled, y_train))\n",
    "print('Score (test data)', model.score(X_test_scaled, y_test))\n",
    "cvs(model, pd.DataFrame(scaler.transform(X)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.46"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even less hidden layers\n",
    "model = MLPClassifier(hidden_layer_sizes=(20), max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Score (training data)', model.score(X_train_scaled, y_train))\n",
    "print('Score (test data)', model.score(X_test_scaled, y_test))\n",
    "cvs(model, pd.DataFrame(scaler.transform(X)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.842\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.6550000000000002"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# More hidden layers\n",
    "model = MLPClassifier(hidden_layer_sizes=(20, 20, 20, 20), max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Score (training data)', model.score(X_train_scaled, y_train))\n",
    "print('Score (test data)', model.score(X_test_scaled, y_test))\n",
    "cvs(model, pd.DataFrame(scaler.transform(X)), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score (training data) 1.0\n",
      "Score (test data) 0.844\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.3375"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Even More hidden layers\n",
    "model = MLPClassifier(hidden_layer_sizes=(20, 20, 20, 20, 20), max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "print('Score (training data)', model.score(X_train_scaled, y_train))\n",
    "print('Score (test data)', model.score(X_test_scaled, y_test))\n",
    "cvs(model, pd.DataFrame(scaler.transform(X)), y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just plot those results quickly, to drive my point home:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Score')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot([1, 2, 3, 4, 5], [3.46, 3.67, 3.725, 3.655, 3.337])\n",
    "plt.xlabel('Number of Hidden Layers')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Score')"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Varying hidden layer size\n",
    "scores = []\n",
    "ns = [1, 3, 5, 10, 20, 50, 100]\n",
    "for n in ns:\n",
    "    model = MLPClassifier(hidden_layer_sizes=(n, n, n), max_iter=1000)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    scores.append(cvs(model, pd.DataFrame(scaler.transform(X)), y))\n",
    "    \n",
    "plt.plot(ns, scores)\n",
    "plt.xlabel('Size of Hidden Layers')\n",
    "plt.ylabel('Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score stops improving around n=20. Any more, and we're making a model that is needlessly complicated. I haven't found a good rule of thumb for this. More complex tasks (eg image inference) need more neurons, very simple tasks do better with ~10 in each hidden layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So, we have a model that outperforms the rest. We might be able to tweak the random forest model to match it's performance, or tweak the model further to squeeze some extra performance out of it. We could also try engineering extra features etc etc. But let's call it good enough, and see if we can use a similar model for some of the other problems we want to try and solve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Regression (position inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "r8 = pd.read_csv('posinf8_500_readings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
